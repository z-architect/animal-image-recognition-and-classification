{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b27d0c7",
   "metadata": {},
   "source": [
    "# LUX Acadamy Data Science BootCamp Project , Dawit Tadesse, Ethiopia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236600c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if on google colab, install kaggle\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the .kaggle directory so that you can configure kaggle using your kaggle.json api key information\n",
    "!mkdir -p ~/.kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00183bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copies the kaggle json file\n",
    "# make sure that the kaggle.json file is uplloaded into colab or that it's inside the project\n",
    "# you can use the upload button on the side menu in colab after clicking the file icon\n",
    "!cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d06b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permissions configuration, \n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check directory \n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45070400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the datasets\n",
    "!kaggle datasets download -d antoreepjana/animals-detection-images-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip the datasets\n",
    "!unzip animals-detection-images-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list the classes in the test directory\n",
    "import os\n",
    "os.listdir(\"./test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creae the paths so we can use them later\n",
    "test_dir = './test'\n",
    "train_dir = './train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the labes into variable so we can use them later and also check how many labes we have\n",
    "# for the softmax classification\n",
    "labels = os.listdir(test_dir)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d49139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a random image to see if all is going well\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "\n",
    "img = mpimg.imread('./test/Brown bear/037ce70dca241ef6.jpg')\n",
    "plt.imshow(img)\n",
    "plt.axis('Off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6802a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's preprocess the images using tensorflows image generator class\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation so that we can get better results on our classification\n",
    "training_data = ImageDataGenerator(rescale = 1./255,\n",
    "                                   width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                  rotation_range=20,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest')\n",
    "# no augmentation on the test data\n",
    "validation_data =  ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = training_data.flow_from_directory(train_dir,\n",
    "                                                    target_size=(224,224),\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size=64)\n",
    "\n",
    "\n",
    "valid_generator = validation_data.flow_from_directory(test_dir,\n",
    "                                                    target_size=(224,224),\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ed163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Lets create our model\n",
    "# our models is a convolutional neural net\n",
    "# with the following layers\n",
    "# 64,64,128,128, Flatten, Dropout, 512, 80\n",
    "# the image's are 224 by 224 with three channels\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 224x224 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(80, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4415a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training parameters, we are using adam optimizer and accuracy for metrics\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e353ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, we let the model figure out the optimal steps \n",
    "# By the way, if running on colab, run it using GPU environment to make \n",
    "# the trianing faster, or else you will be waiting for a long time\n",
    "history = model.fit(train_generator, validation_data = valid_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147db522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model results to visulal see the result\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d87576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your doing this on colab\n",
    "# use the following code to check for an image\n",
    "#from google.colab import files\n",
    "#from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "#uploaded = files.upload()\n",
    "\n",
    "#for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "#  path = fn\n",
    "#  img = load_img(path, target_size=(224, 224))\n",
    "#  x = img_to_array(img)\n",
    "#  x = x  * 1./255\n",
    "#  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "#  images = np.vstack([x])\n",
    "    \n",
    "#  classes = model.predict(images)\n",
    "#  print(fn)\n",
    "#  print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "#This function assumes that the input data is a JSON object containing a \n",
    "#base64-encoded image under the \"image\" key from \n",
    "# the post request.  Can adjust the input format as needed.\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    # Decode the base64 image\n",
    "    img_data = base64.b64decode(data[\"image\"])\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "    # Resize the image to the target size (224,224)\n",
    "    img = img.resize((224, 224), Image.ANTIALIAS)\n",
    "\n",
    "    # Convert the image to a NumPy array and apply the rescale factor\n",
    "    image_array = np.array(img) / 255.0\n",
    "\n",
    "    # Add a batch dimension and return the processed image\n",
    "    return np.expand_dims(image_array, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eed464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the saved TensorFlow model\n",
    "#model = tf.keras.models.load_model(\"my_model.h5\")\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    # Ensure the input data is in the correct format\n",
    "    image_data = preprocess(data)\n",
    "    \n",
    "    # Make a prediction using the loaded model\n",
    "    predictions = model.predict(image_data)\n",
    "    \n",
    "    # Convert the predictions to a JSON response\n",
    "    response = jsonify(predictions.tolist())\n",
    "    # return the raw results to the user making the requests\n",
    "    return response\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd32167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End Note: you can also save the models instead and run the deployment on another .py file on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12998c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
